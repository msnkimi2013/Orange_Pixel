{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8t7UCf3GhkgnttwC9dwb2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msnkimi2013/Orange_Pixel/blob/main/Hand.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGJSTXlyAqnt",
        "outputId": "c3bd9621-b485-493f-b082-d18d435638f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/hand-gesture-recognition-mediapipe-main.zip\n",
            "0e737bb8c45ea03f6fafb1f5dbfe9246c34a8003\n",
            "   creating: hand-gesture-recognition-mediapipe-main/\n",
            "  inflating: hand-gesture-recognition-mediapipe-main/.gitignore  \n",
            "  inflating: hand-gesture-recognition-mediapipe-main/LICENSE  \n",
            "  inflating: hand-gesture-recognition-mediapipe-main/README.md  \n",
            "  inflating: hand-gesture-recognition-mediapipe-main/app.py  \n",
            "  inflating: hand-gesture-recognition-mediapipe-main/keypoint_classification.ipynb  \n",
            "  inflating: hand-gesture-recognition-mediapipe-main/keypoint_classification_EN.ipynb  \n",
            "   creating: hand-gesture-recognition-mediapipe-main/model/\n",
            "  inflating: hand-gesture-recognition-mediapipe-main/model/__init__.py  \n",
            "   creating: hand-gesture-recognition-mediapipe-main/model/keypoint_classifier/\n",
            "  inflating: hand-gesture-recognition-mediapipe-main/model/keypoint_classifier/keypoint.csv  \n",
            "  inflating: hand-gesture-recognition-mediapipe-main/model/keypoint_classifier/keypoint_classifier.hdf5  \n",
            "  inflating: hand-gesture-recognition-mediapipe-main/model/keypoint_classifier/keypoint_classifier.py  \n",
            "  inflating: hand-gesture-recognition-mediapipe-main/model/keypoint_classifier/keypoint_classifier.tflite  \n",
            " extracting: hand-gesture-recognition-mediapipe-main/model/keypoint_classifier/keypoint_classifier_label.csv  \n",
            "   creating: hand-gesture-recognition-mediapipe-main/model/point_history_classifier/\n",
            "  inflating: hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history.csv  \n",
            "  inflating: hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.hdf5  \n",
            "  inflating: hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.py  \n",
            "  inflating: hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier.tflite  \n",
            "  inflating: hand-gesture-recognition-mediapipe-main/model/point_history_classifier/point_history_classifier_label.csv  \n",
            "  inflating: hand-gesture-recognition-mediapipe-main/point_history_classification.ipynb  \n",
            "   creating: hand-gesture-recognition-mediapipe-main/utils/\n",
            " extracting: hand-gesture-recognition-mediapipe-main/utils/__init__.py  \n",
            "  inflating: hand-gesture-recognition-mediapipe-main/utils/cvfpscalc.py  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/hand-gesture-recognition-mediapipe-main.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/hand-gesture-recognition-mediapipe-main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPuxx86nA3Xo",
        "outputId": "eac9cd31-f405-4858-82bf-5a7fb73633b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hand-gesture-recognition-mediapipe-main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZFqXiwbA8-O",
        "outputId": "2a5a13f7-5862-4665-fc3b-3cbed240699e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hand-gesture-recognition-mediapipe-main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbrQWeuSBMSl",
        "outputId": "b59b7d7f-25a7-42f4-9001-48ab1308f814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.5.26)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.23.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.3 sounddevice-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import copy\n",
        "import argparse\n",
        "import itertools\n",
        "from collections import Counter\n",
        "from collections import deque\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "\n",
        "from utils import CvFpsCalc\n",
        "from model import KeyPointClassifier\n",
        "from model import PointHistoryClassifier"
      ],
      "metadata": {
        "id": "maOWJkYBA-Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_args():\n",
        "#     parser = argparse.ArgumentParser()\n",
        "\n",
        "#     parser.add_argument(\"--device\", type=int, default=0)\n",
        "#     parser.add_argument(\"--width\", help='cap width', type=int, default=960)\n",
        "#     parser.add_argument(\"--height\", help='cap height', type=int, default=540)\n",
        "\n",
        "#     parser.add_argument('--use_static_image_mode', action='store_true')\n",
        "#     parser.add_argument(\"--min_detection_confidence\",\n",
        "#                         help='min_detection_confidence',\n",
        "#                         type=float,\n",
        "#                         default=0.7)\n",
        "#     parser.add_argument(\"--min_tracking_confidence\",\n",
        "#                         help='min_tracking_confidence',\n",
        "#                         type=int,\n",
        "#                         default=0.5)\n",
        "\n",
        "#     args = parser.parse_args()\n",
        "\n",
        "#     return args"
      ],
      "metadata": {
        "id": "G8F0ios8PTYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def select_mode(key, mode):\n",
        "    number = -1\n",
        "    if 48 <= key <= 57:  # 0 ~ 9\n",
        "        number = key - 48\n",
        "    if key == 110:  # n\n",
        "        mode = 0\n",
        "    if key == 107:  # k\n",
        "        mode = 1\n",
        "    if key == 104:  # h\n",
        "        mode = 2\n",
        "    return number, mode\n",
        "\n",
        "\n",
        "def calc_bounding_rect(image, landmarks):\n",
        "    image_width, image_height = image.shape[1], image.shape[0]\n",
        "\n",
        "    landmark_array = np.empty((0, 2), int)\n",
        "\n",
        "    for _, landmark in enumerate(landmarks.landmark):\n",
        "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
        "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
        "\n",
        "        landmark_point = [np.array((landmark_x, landmark_y))]\n",
        "\n",
        "        landmark_array = np.append(landmark_array, landmark_point, axis=0)\n",
        "\n",
        "    x, y, w, h = cv.boundingRect(landmark_array)\n",
        "\n",
        "    return [x, y, x + w, y + h]\n",
        "\n",
        "\n",
        "def calc_landmark_list(image, landmarks):\n",
        "    image_width, image_height = image.shape[1], image.shape[0]\n",
        "\n",
        "    landmark_point = []\n",
        "\n",
        "    # Keypoint\n",
        "    for _, landmark in enumerate(landmarks.landmark):\n",
        "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
        "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
        "        # landmark_z = landmark.z\n",
        "\n",
        "        landmark_point.append([landmark_x, landmark_y])\n",
        "\n",
        "    return landmark_point\n",
        "\n",
        "\n",
        "def pre_process_landmark(landmark_list):\n",
        "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
        "\n",
        "    # Convert to relative coordinates\n",
        "    base_x, base_y = 0, 0\n",
        "    for index, landmark_point in enumerate(temp_landmark_list):\n",
        "        if index == 0:\n",
        "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
        "\n",
        "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
        "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
        "\n",
        "    # Convert to a one-dimensional list\n",
        "    temp_landmark_list = list(\n",
        "        itertools.chain.from_iterable(temp_landmark_list))\n",
        "\n",
        "    # Normalization\n",
        "    max_value = max(list(map(abs, temp_landmark_list)))\n",
        "\n",
        "    def normalize_(n):\n",
        "        return n / max_value\n",
        "\n",
        "    temp_landmark_list = list(map(normalize_, temp_landmark_list))\n",
        "\n",
        "    return temp_landmark_list\n",
        "\n",
        "\n",
        "def pre_process_point_history(image, point_history):\n",
        "    image_width, image_height = image.shape[1], image.shape[0]\n",
        "\n",
        "    temp_point_history = copy.deepcopy(point_history)\n",
        "\n",
        "    # Convert to relative coordinates\n",
        "    base_x, base_y = 0, 0\n",
        "    for index, point in enumerate(temp_point_history):\n",
        "        if index == 0:\n",
        "            base_x, base_y = point[0], point[1]\n",
        "\n",
        "        temp_point_history[index][0] = (temp_point_history[index][0] -\n",
        "                                        base_x) / image_width\n",
        "        temp_point_history[index][1] = (temp_point_history[index][1] -\n",
        "                                        base_y) / image_height\n",
        "\n",
        "    # Convert to a one-dimensional list\n",
        "    temp_point_history = list(\n",
        "        itertools.chain.from_iterable(temp_point_history))\n",
        "\n",
        "    return temp_point_history\n",
        "\n",
        "\n",
        "def logging_csv(number, mode, landmark_list, point_history_list):\n",
        "    if mode == 0:\n",
        "        pass\n",
        "    if mode == 1 and (0 <= number <= 9):\n",
        "        csv_path = 'model/keypoint_classifier/keypoint.csv'\n",
        "        with open(csv_path, 'a', newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([number, *landmark_list])\n",
        "    if mode == 2 and (0 <= number <= 9):\n",
        "        csv_path = 'model/point_history_classifier/point_history.csv'\n",
        "        with open(csv_path, 'a', newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([number, *point_history_list])\n",
        "    return\n",
        "\n",
        "\n",
        "def draw_landmarks(image, landmark_point):\n",
        "    if len(landmark_point) > 0:\n",
        "        # Thumb\n",
        "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),\n",
        "                (255, 255, 255), 2)\n",
        "        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),\n",
        "                (255, 255, 255), 2)\n",
        "\n",
        "        # Index finger\n",
        "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),\n",
        "                (255, 255, 255), 2)\n",
        "        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),\n",
        "                (255, 255, 255), 2)\n",
        "        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),\n",
        "                (255, 255, 255), 2)\n",
        "\n",
        "        # Middle finger\n",
        "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),\n",
        "                (255, 255, 255), 2)\n",
        "        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),\n",
        "                (255, 255, 255), 2)\n",
        "        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),\n",
        "                (255, 255, 255), 2)\n",
        "\n",
        "        # Ring finger\n",
        "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),\n",
        "                (255, 255, 255), 2)\n",
        "        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),\n",
        "                (255, 255, 255), 2)\n",
        "        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),\n",
        "                (255, 255, 255), 2)\n",
        "\n",
        "        # Little finger\n",
        "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),\n",
        "                (255, 255, 255), 2)\n",
        "        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),\n",
        "                (255, 255, 255), 2)\n",
        "        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),\n",
        "                (255, 255, 255), 2)\n",
        "\n",
        "        # Palm\n",
        "        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),\n",
        "                (255, 255, 255), 2)\n",
        "        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),\n",
        "                (255, 255, 255), 2)\n",
        "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),\n",
        "                (255, 255, 255), 2)\n",
        "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),\n",
        "                (255, 255, 255), 2)\n",
        "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),\n",
        "                (255, 255, 255), 2)\n",
        "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),\n",
        "                (255, 255, 255), 2)\n",
        "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),\n",
        "                (0, 0, 0), 6)\n",
        "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),\n",
        "                (255, 255, 255), 2)\n",
        "\n",
        "    # Key Points\n",
        "    for index, landmark in enumerate(landmark_point):\n",
        "        if index == 0:  # 手首1\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
        "        if index == 1:  # 手首2\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
        "        if index == 2:  # 親指：付け根\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
        "        if index == 3:  # 親指：第1関節\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
        "        if index == 4:  # 親指：指先\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
        "        if index == 5:  # 人差指：付け根\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
        "        if index == 6:  # 人差指：第2関節\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
        "        if index == 7:  # 人差指：第1関節\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
        "        if index == 8:  # 人差指：指先\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
        "        if index == 9:  # 中指：付け根\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
        "        if index == 10:  # 中指：第2関節\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
        "        if index == 11:  # 中指：第1関節\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
        "        if index == 12:  # 中指：指先\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
        "        if index == 13:  # 薬指：付け根\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
        "        if index == 14:  # 薬指：第2関節\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
        "        if index == 15:  # 薬指：第1関節\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
        "        if index == 16:  # 薬指：指先\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
        "        if index == 17:  # 小指：付け根\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
        "        if index == 18:  # 小指：第2関節\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
        "        if index == 19:  # 小指：第1関節\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
        "        if index == 20:  # 小指：指先\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
        "                      -1)\n",
        "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_bounding_rect(use_brect, image, brect):\n",
        "    if use_brect:\n",
        "        # Outer rectangle\n",
        "        cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]),\n",
        "                     (0, 0, 0), 1)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_info_text(image, brect, handedness, hand_sign_text,\n",
        "                   finger_gesture_text):\n",
        "    cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[1] - 22),\n",
        "                 (0, 0, 0), -1)\n",
        "\n",
        "    info_text = handedness.classification[0].label[0:]\n",
        "    if hand_sign_text != \"\":\n",
        "        info_text = info_text + ':' + hand_sign_text\n",
        "\n",
        "        print(hand_sign_text)                                                               # JIN\n",
        "\n",
        "    cv.putText(image, info_text, (brect[0] + 5, brect[1] - 4),\n",
        "               cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv.LINE_AA)\n",
        "\n",
        "    if finger_gesture_text != \"\":\n",
        "        cv.putText(image, \"Finger Gesture:\" + finger_gesture_text, (10, 60),\n",
        "                   cv.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 4, cv.LINE_AA)\n",
        "        cv.putText(image, \"Finger Gesture:\" + finger_gesture_text, (10, 60),\n",
        "                   cv.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2,\n",
        "                   cv.LINE_AA)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_point_history(image, point_history):\n",
        "    for index, point in enumerate(point_history):\n",
        "        if point[0] != 0 and point[1] != 0:\n",
        "            cv.circle(image, (point[0], point[1]), 1 + int(index / 2),\n",
        "                      (152, 251, 152), 2)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def draw_info(image, fps, mode, number):\n",
        "    cv.putText(image, \"FPS:\" + str(fps), (10, 30), cv.FONT_HERSHEY_SIMPLEX,\n",
        "               1.0, (0, 0, 0), 4, cv.LINE_AA)\n",
        "    cv.putText(image, \"FPS:\" + str(fps), (10, 30), cv.FONT_HERSHEY_SIMPLEX,\n",
        "               1.0, (255, 255, 255), 2, cv.LINE_AA)\n",
        "\n",
        "    mode_string = ['Logging Key Point', 'Logging Point History']\n",
        "    if 1 <= mode <= 2:\n",
        "        cv.putText(image, \"MODE:\" + mode_string[mode - 1], (10, 90),\n",
        "                   cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
        "                   cv.LINE_AA)\n",
        "        if 0 <= number <= 9:\n",
        "            cv.putText(image, \"NUM:\" + str(number), (10, 110),\n",
        "                       cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
        "                       cv.LINE_AA)\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "0sYg31LvBU8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Argument parsing #################################################################\n",
        "# args = get_args()\n",
        "\n",
        "cap_device = 0\n",
        "cap_width = 960\n",
        "cap_height = 540\n",
        "\n",
        "use_static_image_mode = 'store_true'\n",
        "min_detection_confidence = 0.7\n",
        "min_tracking_confidence = 0.5                                                            #JIN\n",
        "\n",
        "use_brect = True\n",
        "\n",
        "# Camera preparation ###############################################################\n",
        "cap = cv.VideoCapture(cap_device)\n",
        "cap.set(cv.CAP_PROP_FRAME_WIDTH, cap_width)\n",
        "cap.set(cv.CAP_PROP_FRAME_HEIGHT, cap_height)\n",
        "\n",
        "# Model load #############################################################\n",
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(static_image_mode=use_static_image_mode,max_num_hands=2,min_detection_confidence=min_detection_confidence,min_tracking_confidence=min_tracking_confidence,)\n",
        "\n",
        "keypoint_classifier = KeyPointClassifier()\n",
        "\n",
        "point_history_classifier = PointHistoryClassifier()\n",
        "\n",
        "# Read labels ###########################################################\n",
        "with open('model/keypoint_classifier/keypoint_classifier_label.csv', 'r', encoding='utf-8-sig') as f:                                            #utf-8-sig\n",
        "    keypoint_classifier_labels = csv.reader(f)\n",
        "    keypoint_classifier_labels = [ row[0] for row in keypoint_classifier_labels ]\n",
        "with open('model/point_history_classifier/point_history_classifier_label.csv', encoding='utf-8-sig') as f:\n",
        "    point_history_classifier_labels = csv.reader(f)\n",
        "    point_history_classifier_labels = [row[0] for row in point_history_classifier_labels]\n",
        "\n",
        "# FPS Measurement ########################################################\n",
        "cvFpsCalc = CvFpsCalc(buffer_len=10)\n",
        "\n",
        "# Coordinate history #################################################################\n",
        "history_length = 16\n",
        "point_history = deque(maxlen=history_length)\n",
        "\n",
        "# Finger gesture history ################################################\n",
        "finger_gesture_history = deque(maxlen=history_length)\n",
        "\n",
        "#  ########################################################################\n",
        "mode = 0"
      ],
      "metadata": {
        "id": "GYrqBuXXPWnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# opencv print Korean solution\n",
        "# !pip install pillow\n",
        "from PIL import ImageFont, ImageDraw, Image\n",
        "\n",
        "font = ImageFont.truetype('/content/MaruBuri-Bold.ttf', 100)"
      ],
      "metadata": {
        "id": "ECmqT4c7uIy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Camera capture #####################################################\n",
        "image = cv.imread('/content/hand-gesture-recognition-mediapipe-main/test_image/ㄴ.jpg')\n",
        "image = cv.flip(image, 1)  # Mirror display\n",
        "debug_image = copy.deepcopy(image)\n",
        "\n",
        "# Detection implementation #############################################################\n",
        "image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "\n",
        "image.flags.writeable = False\n",
        "results = hands.process(image)\n",
        "image.flags.writeable = True\n",
        "\n",
        "#  ####################################################################\n",
        "if results.multi_hand_landmarks is not None:\n",
        "    for hand_landmarks, handedness in zip(results.multi_hand_landmarks,results.multi_handedness):\n",
        "        # print(hand_landmarks)                                               # JIN\n",
        "\n",
        "        # Bounding box calculation\n",
        "        brect = calc_bounding_rect(debug_image, hand_landmarks)\n",
        "        # Landmark calculation\n",
        "        landmark_list = calc_landmark_list(debug_image, hand_landmarks)\n",
        "\n",
        "        # print(landmark_list[0])\n",
        "\n",
        "        # Conversion to relative coordinates / normalized coordinates\n",
        "        pre_processed_landmark_list = pre_process_landmark(landmark_list)\n",
        "\n",
        "        # print(pre_processed_landmark_list)\n",
        "\n",
        "        pre_processed_point_history_list = pre_process_point_history(debug_image, point_history)\n",
        "        # Write to the dataset file\n",
        "        # logging_csv(number, mode, pre_processed_landmark_list, pre_processed_point_history_list)\n",
        "\n",
        "        # Hand sign classification\n",
        "        hand_sign_id = keypoint_classifier(pre_processed_landmark_list)\n",
        "\n",
        "        print(hand_sign_id)                                                                                # JIN\n",
        "\n",
        "        if hand_sign_id == 2:  # Point gesture\n",
        "            point_history.append(landmark_list[8])\n",
        "        else:\n",
        "            point_history.append([0, 0])\n",
        "\n",
        "        # Finger gesture classification\n",
        "        finger_gesture_id = 0\n",
        "        point_history_len = len(pre_processed_point_history_list)\n",
        "        if point_history_len == (history_length * 2):\n",
        "            finger_gesture_id = point_history_classifier(pre_processed_point_history_list)\n",
        "\n",
        "        # Calculates the gesture IDs in the latest detection\n",
        "        finger_gesture_history.append(finger_gesture_id)\n",
        "\n",
        "        # print(finger_gesture_id)                                                                            #JIN\n",
        "\n",
        "        most_common_fg_id = Counter(finger_gesture_history).most_common()\n",
        "\n",
        "        # Drawing part\n",
        "        debug_image = draw_bounding_rect(use_brect, debug_image, brect)\n",
        "        debug_image = draw_landmarks(debug_image, landmark_list)\n",
        "        # debug_image = draw_info_text( debug_image, brect, handedness, keypoint_classifier_labels[hand_sign_id], point_history_classifier_labels[most_common_fg_id[0][0]])\n",
        "\n",
        "        print(keypoint_classifier_labels)\n",
        "        # print(keypoint_classifier_labels[finger_gesture_id])                                                      #JIN\n",
        "        print(keypoint_classifier_labels[hand_sign_id])                                                      #JIN\n",
        "\n",
        "\n",
        "        # opencv print Korean solution\n",
        "        img_pil = Image.fromarray(image)\n",
        "        draw = ImageDraw.Draw(img_pil)\n",
        "        draw.text((50, 100), keypoint_classifier_labels[hand_sign_id], (0, 0, 255), font = font)\n",
        "        image = np.array(img_pil)\n",
        "\n",
        "        # opencv print Korean as ????\n",
        "        # cv.putText(image, keypoint_classifier_labels[hand_sign_id], (50,100), cv.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 2, cv.LINE_AA)\n",
        "        cv.imwrite('/content/hand-gesture-recognition-mediapipe-main/result_image/ㄴ.jpg', image)\n",
        "\n",
        "else:\n",
        "    point_history.append([0, 0])\n",
        "\n",
        "debug_image = draw_point_history(debug_image, point_history)\n",
        "# debug_image = draw_info(debug_image, fps, mode, number)\n",
        "\n",
        "# Screen reflection #############################################################\n",
        "# cv.imshow('Hand Gesture Recognition', debug_image)\n",
        "\n",
        "# cap.release()\n",
        "# cv.destroyAllWindows()"
      ],
      "metadata": {
        "id": "oir0vCW_TEZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OnJ5D-L7R3-x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}